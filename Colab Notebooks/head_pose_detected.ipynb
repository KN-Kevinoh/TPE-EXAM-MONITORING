{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import utils\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_NUM = 66\n",
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE=16\n",
    "EPOCHS=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create HopeNet Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model create\n",
    "class Hopenet:\n",
    "    def __init__(self, dataset, class_num, batch_size, input_size):\n",
    "        self.class_num = class_num\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.idx_tensor = [idx for idx in range(self.class_num)]\n",
    "        self.idx_tensor = tf.Variable(np.array(self.idx_tensor, dtype=np.float32))\n",
    "        self.dataset = dataset\n",
    "        self.model = self.__create_model()\n",
    "        \n",
    "    \n",
    "    def multi_loss(self, y_true, y_pred, alpha=0.5):\n",
    "        \"\"\" Calculate the multi-part loss: classification_loss + alpha * regression_loss\n",
    "        Args:\n",
    "          y_true: the true label\n",
    "          y_pred: the predicted label\n",
    "          alpha: the alpha value\n",
    "        Returns:\n",
    "          total_loss: the multipart loss\n",
    "        \"\"\"\n",
    "\n",
    "        # classification loss\n",
    "        y_true_bin = y_true[:, 0]\n",
    "        y_true_bin = tf.cast(y_true_bin, tf.int64)\n",
    "        y_true_bin = tf.one_hot(y_true_bin, 66)\n",
    "        cls_loss = tf.losses.softmax_cross_entropy(y_true_bin, y_pred)\n",
    "\n",
    "        # regression loss\n",
    "        y_true_cont = y_true[:, 1]\n",
    "        y_pred_cont = tf.nn.softmax(y_pred)\n",
    "        y_pred_cont = tf.reduce_sum(y_pred_cont * self.idx_tensor, 1) * 3 - 99\n",
    "        mse_loss = tf.compat.v1.losses.mean_squared_error(y_true_cont, y_pred_cont)\n",
    "\n",
    "        total_loss = cls_loss + alpha * mse_loss\n",
    "        return total_loss\n",
    "    \n",
    "        \n",
    "    def __create_model(self):\n",
    "        inputs = tf.keras.layers.Input(shape=(self.input_size, self.input_size, 3))\n",
    "\n",
    "        resnet = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "        feature = resnet(inputs)\n",
    "        feature = tf.keras.layers.Flatten()(feature)\n",
    "        feature = tf.keras.layers.Dropout(0.5)(feature)\n",
    "\n",
    "        yaw = tf.keras.layers.Dense(name='yaw', units=self.class_num, activation=None)(feature)\n",
    "        pitch = tf.keras.layers.Dense(name='pitch', units=self.class_num, activation=None)(feature)\n",
    "        roll = tf.keras.layers.Dense(name='roll', units=self.class_num, activation=None)(feature)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=[yaw, pitch, roll])\n",
    "        \n",
    "        #for layer in resnet.layers:\n",
    "            #layer.trainable = False\n",
    "\n",
    "        model.compile(\n",
    "          optimizer='adam',\n",
    "            loss={\n",
    "              'yaw': self.multi_loss,\n",
    "              'pitch': self.multi_loss,\n",
    "              'roll': self.multi_loss,\n",
    "            }\n",
    "           , metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    \n",
    "    def train(self, model_path, max_epoches=EPOCHS, load_weight=True):\n",
    "        self.model.summary()\n",
    "        \n",
    "        if load_weight:\n",
    "            self.model.load_weights(model_path)\n",
    "        else:\n",
    "            self.model.fit_generator(generator=self.dataset.data_generator(test=False),\n",
    "                                    epochs=max_epoches,\n",
    "                                    steps_per_epoch=self.dataset.train_num // self.batch_size,\n",
    "                                    max_queue_size=10,\n",
    "                                    workers=1,\n",
    "                                    verbose=1)\n",
    "\n",
    "            self.model.save(model_path)\n",
    "            \n",
    "    def test(self, save_dir):\n",
    "        for i, (images, [batch_yaw, batch_pitch, batch_roll], names) in enumerate(self.dataset.data_generator(test=True)):\n",
    "            predictions = self.model.predict(images, batch_size=self.batch_size, verbose=1)\n",
    "            predictions = np.asarray(predictions)\n",
    "            pred_cont_yaw = tf.reduce_sum(tf.nn.softmax(predictions[0,:,:]) * self.idx_tensor, 1) * 3 - 99\n",
    "            pred_cont_pitch = tf.reduce_sum(tf.nn.softmax(predictions[1,:,:]) * self.idx_tensor, 1) * 3 - 99\n",
    "            pred_cont_roll = tf.reduce_sum(tf.nn.softmax(predictions[2,:,:]) * self.idx_tensor, 1) * 3 - 99\n",
    "            # print(pred_cont_yaw.shape)\n",
    "            \n",
    "            self.dataset.save_test(names[0], save_dir, [pred_cont_yaw[0], pred_cont_pitch[0], pred_cont_roll[0]])\n",
    "            \n",
    "    def test_online(self, face_imgs):\n",
    "        batch_x = np.array(face_imgs, dtype=np.float32)\n",
    "        predictions = self.model.predict(batch_x, batch_size=1, verbose=1)\n",
    "        predictions = np.asarray(predictions)\n",
    "        # print(predictions)\n",
    "        pred_cont_yaw = tf.reduce_sum(tf.nn.softmax(predictions[0, :, :]) * self.idx_tensor, 1) * 3 - 99\n",
    "        pred_cont_pitch = tf.reduce_sum(tf.nn.softmax(predictions[1, :, :]) * self.idx_tensor, 1) * 3 - 99\n",
    "        pred_cont_roll = tf.reduce_sum(tf.nn.softmax(predictions[2, :, :]) * self.idx_tensor, 1) * 3 - 99\n",
    "        \n",
    "        return pred_cont_yaw[0], pred_cont_pitch[0], pred_cont_roll[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets function\n",
    "def split_samples(samples_file, train_file, test_file, ratio=0.8):\n",
    "    with open(samples_file) as samples_fp:\n",
    "        lines = samples_fp.readlines()\n",
    "        random.shuffle(lines)\n",
    "\n",
    "        train_num = int(len(lines) * ratio)\n",
    "        test_num = len(lines) - train_num\n",
    "        count = 0\n",
    "        data = []\n",
    "        for line in lines:\n",
    "            count += 1\n",
    "            data.append(line)\n",
    "            if count == train_num:\n",
    "                with open(train_file, \"w+\") as train_fp:\n",
    "                    for d in data:\n",
    "                        train_fp.write(d)\n",
    "                data = []\n",
    "\n",
    "            if count == train_num + test_num:\n",
    "                with open(test_file, \"w+\") as test_fp:\n",
    "                    for d in data:\n",
    "                        test_fp.write(d)\n",
    "                data = []\n",
    "    return train_num, test_num\n",
    "\n",
    "def get_list_from_filenames(file_path):\n",
    "    with open(file_path) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets AFLW2000\n",
    "class AFLW2000:\n",
    "    def __init__(self, data_dir, data_file, batch_size=16, input_size=224):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_file = data_file\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.train_file = None\n",
    "        self.test_file = None\n",
    "        self.__gen_filename_list(os.path.join(self.data_dir, self.data_file))\n",
    "        self.train_num, self.test_num = self.__gen_train_test_file(os.path.join(self.data_dir, '/opt/Documents/I.F.I-Vietnam/COURS_IFI/TPE/My work/datasets/BIWI/train.txt'),\n",
    "                                                                   os.path.join(self.data_dir, '/opt/Documents/I.F.I-Vietnam/COURS_IFI/TPE/My work/datasets/BIWI/test.txt'))\n",
    "    def __get_ypr_from_mat(self, mat_path):\n",
    "        mat = sio.loadmat(mat_path)\n",
    "        pre_pose_params = mat['Pose_Para'][0]\n",
    "        pose_params = pre_pose_params[:3]\n",
    "        return pose_params\n",
    "\n",
    "    def __get_pt2d_from_mat(self, mat_path):\n",
    "        mat = sio.loadmat(mat_path)\n",
    "        pt2d = mat['pt2d']\n",
    "        return pt2d\n",
    "    \n",
    "    def __get_input_img(self, data_dir, file_name, img_ext='.jpg', annot_ext='.mat'):\n",
    "        img = cv2.imread(os.path.join(data_dir, file_name + img_ext))\n",
    "        pt2d = self.__get_pt2d_from_mat(os.path.join(data_dir, file_name + annot_ext))\n",
    "        \n",
    "        # Crop the face loosely\n",
    "        x_min = min(pt2d[0, :])\n",
    "        y_min = min(pt2d[1, :])\n",
    "        x_max = max(pt2d[0, :])\n",
    "        y_max = max(pt2d[1, :])\n",
    "        \n",
    "        Lx = abs(x_max - x_min)\n",
    "        Ly = abs(y_max - y_min)\n",
    "        Lmax = max(Lx, Ly) * 1.5\n",
    "        center_x = x_min + Lx // 2\n",
    "        center_y = y_min + Ly // 2\n",
    "        \n",
    "        x_min = center_x - Lmax // 2\n",
    "        x_max = center_x + Lmax // 2\n",
    "        y_min = center_y - Lmax // 2\n",
    "        y_max = center_y + Lmax // 2\n",
    "        \n",
    "        if x_min < 0:\n",
    "            y_max -= abs(x_min)\n",
    "            x_min = 0\n",
    "        if y_min < 0:\n",
    "            x_max -= abs(y_min)\n",
    "            y_min = 0\n",
    "        if x_max > img.shape[1]:\n",
    "            y_min += abs(x_max - img.shape[1])\n",
    "            x_max = img.shape[1]\n",
    "        if y_max > img.shape[0]:\n",
    "            x_min += abs(y_max - img.shape[0])\n",
    "            y_max = img.shape[0]\n",
    "        \n",
    "        # print(\"x_min:{},x_max:{},y_min:{},y_max{}\".format(x_min, x_max, y_min, y_max))\n",
    "        crop_img = img[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "        \n",
    "        # print(crop_img.shape)\n",
    "        # cv2.imshow('crop_img', crop_img)\n",
    "        # cv2.waitKey(0)\n",
    "        crop_img = np.asarray(cv2.resize(crop_img, (self.input_size, self.input_size)))\n",
    "        normed_img = (crop_img - crop_img.mean()) / crop_img.std()\n",
    "        # print(normed_img)\n",
    "        return normed_img\n",
    "    \n",
    "    def __get_input_label(self, data_dir, file_name, annot_ext='.mat'):\n",
    "        # We get the pose in radians\n",
    "        pose = self.__get_ypr_from_mat(os.path.join(data_dir, file_name + annot_ext))\n",
    "        \n",
    "        # And convert to degrees.\n",
    "        yaw = pose[1] * 180.0 / np.pi\n",
    "        pitch = pose[0] * 180.0 / np.pi\n",
    "        roll = pose[2] * 180.0 / np.pi\n",
    "        \n",
    "        cont_labels = [yaw, pitch, roll]\n",
    "        \n",
    "        # print(cont_labels)\n",
    "        # Bin values\n",
    "        bins = np.array(range(-99, 99, 3))\n",
    "        bin_labels = np.digitize([yaw, pitch, roll], bins) - 1\n",
    "        \n",
    "        return bin_labels, cont_labels\n",
    "\n",
    "    def __gen_filename_list(self, filename_list_file):\n",
    "        if not os.path.exists(filename_list_file):\n",
    "            with open(filename_list_file, 'w+') as tlf:\n",
    "                for root, dirs, files in os.walk(self.data_dir):\n",
    "                    for f in files:\n",
    "                        if os.path.splitext(f)[1] == '.jpg':\n",
    "                            tlf.write(os.path.splitext(f)[0] + '\\n')\n",
    "                            \n",
    "    def __gen_train_test_file(self, train_file, test_file):\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        return split_samples(os.path.join(self.data_dir, self.data_file), self.train_file, self.test_file, ratio=0.8)\n",
    "\n",
    "    def train_num(self):\n",
    "        return self.train_num\n",
    "\n",
    "    def test_num(self):\n",
    "        return self.test_num\n",
    "    \n",
    "    def save_test(self, name, save_dir, prediction):\n",
    "        img_path = os.path.join(self.data_dir, name + '.jpg')\n",
    "        # print(img_path)\n",
    "    \n",
    "        cv2_img = cv2.imread(img_path)\n",
    "        cv2_img = utils.draw_axis(cv2_img, prediction[0], prediction[1], prediction[2], tdx=200, tdy=200,\n",
    "                            size=100)\n",
    "        save_path = os.path.join(save_dir, name + '.jpg')\n",
    "        # print(save_path)\n",
    "        cv2.imwrite(save_path, cv2_img)\n",
    "        \n",
    "    def data_generator(self, shuffle=True, test=False):\n",
    "        sample_file = self.train_file\n",
    "        if test:\n",
    "            sample_file = self.test_file\n",
    "            \n",
    "        filenames = get_list_from_filenames(sample_file)\n",
    "        file_num = len(filenames)\n",
    "        print(file_num)\n",
    "        while True:\n",
    "            if shuffle:\n",
    "                idx = np.random.permutation(range(file_num))\n",
    "                filenames = np.array(filenames)[idx]\n",
    "            max_num = file_num - (file_num % self.batch_size)\n",
    "            for i in range(0, max_num, self.batch_size):\n",
    "                batch_x = []\n",
    "                batch_yaw = []\n",
    "                batch_pitch = []\n",
    "                batch_roll = []\n",
    "                names = []\n",
    "                for j in range(self.batch_size):\n",
    "                    img = self.__get_input_img(self.data_dir, filenames[i + j])\n",
    "                    bin_labels, cont_labels = self.__get_input_label(self.data_dir, filenames[i + j])\n",
    "                    # print(img.shape)\n",
    "                    batch_x.append(img)\n",
    "                    batch_yaw.append([bin_labels[0], cont_labels[0]])\n",
    "                    batch_pitch.append([bin_labels[1], cont_labels[1]])\n",
    "                    batch_roll.append([bin_labels[2], cont_labels[2]])\n",
    "                    names.append(filenames[i + j])\n",
    "                \n",
    "                batch_x = np.array(batch_x, dtype=np.float32)\n",
    "                batch_yaw = np.array(batch_yaw)\n",
    "                batch_pitch = np.array(batch_pitch)\n",
    "                batch_roll = np.array(batch_roll)\n",
    "                \n",
    "                if test:\n",
    "                    yield (batch_x, [batch_yaw, batch_pitch, batch_roll], names)\n",
    "                else:\n",
    "                    yield (batch_x, [batch_yaw, batch_pitch, batch_roll])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset BIWI\n",
    "class Biwi:\n",
    "    def __init__(self, data_dir, data_file, batch_size=16, input_size=224, ratio=0.8):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_file = data_file\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.train_file = None\n",
    "        self.test_file = None\n",
    "        self.__gen_filename_list(os.path.join(self.data_dir, self.data_file))\n",
    "        self.train_num, self.test_num = self.__gen_train_test_file(os.path.join(self.data_dir, '/opt/Documents/I.F.I-Vietnam/COURS_IFI/TPE/My work/datasets/BIWI/train.txt'),\n",
    "                                                                   os.path.join(self.data_dir, '/opt/Documents/I.F.I-Vietnam/COURS_IFI/TPE/My work/datasets/BIWI/test.txt'), ratio=ratio)\n",
    "        \n",
    "    def __get_input_img(self, data_dir, file_name, img_ext='.png', annot_ext='.txt'):\n",
    "        img = cv2.imread(os.path.join(data_dir, file_name + '_rgb' + img_ext))\n",
    "        bbox_path = os.path.join(data_dir, file_name.split('/')[0] + '/bbox.txt')\n",
    "        \n",
    "        # Load bounding box\n",
    "        bbox = open(bbox_path, 'r')\n",
    "        line = bbox.readline().split(' ')\n",
    "        if len(line) < 4:\n",
    "            x_min, x_max, y_min, y_max = 0, img.size[0], 0, img.size[1]\n",
    "        else:\n",
    "            x_min, x_max, y_min, y_max = [float(line[0]), float(line[1]), float(line[2]), float(line[3])]\n",
    "        bbox.close()\n",
    "    \n",
    "        # Loosely crop face\n",
    "        k = 0.3\n",
    "        x_min -= k * abs(x_max - x_min)\n",
    "        y_min -= k * abs(y_max - y_min)\n",
    "        x_max += k * abs(x_max - x_min)\n",
    "        y_max += k * abs(y_max - y_min)\n",
    "        crop_img = img[int(y_min): int(y_max), int(x_min): int(x_max)]\n",
    "        \n",
    "        # print(crop_img.shape)\n",
    "        # cv2.imshow('crop_img', crop_img)\n",
    "        # cv2.waitKey(0)\n",
    "        \n",
    "        crop_img = cv2.resize(crop_img, (self.input_size, self.input_size))\n",
    "        \n",
    "        crop_img = np.asarray(crop_img)\n",
    "        normed_img = (crop_img - crop_img.mean())/crop_img.std()\n",
    "        \n",
    "        return normed_img\n",
    "        \n",
    "    \n",
    "    def __get_input_label(self, data_dir, file_name, annot_ext='.txt'):\n",
    "        # Load pose in degrees\n",
    "        pose_path = os.path.join(data_dir, file_name + '_pose' + annot_ext)\n",
    "        pose_annot = open(pose_path, 'r')\n",
    "        R = []\n",
    "        for line in pose_annot:\n",
    "            line = line.strip('\\n').split(' ')\n",
    "            l = []\n",
    "            if line[0] != '':\n",
    "                for nb in line:\n",
    "                    if nb == '':\n",
    "                        continue\n",
    "                    l.append(float(nb))\n",
    "                R.append(l)\n",
    "        \n",
    "        R = np.array(R)\n",
    "        T = R[3, :]\n",
    "        R = R[:3, :]\n",
    "        pose_annot.close()\n",
    "        \n",
    "        R = np.transpose(R)\n",
    "        \n",
    "        roll = -np.arctan2(R[1][0], R[0][0]) * 180 / np.pi\n",
    "        yaw = -np.arctan2(-R[2][0], np.sqrt(R[2][1] ** 2 + R[2][2] ** 2)) * 180 / np.pi\n",
    "        pitch = np.arctan2(R[2][1], R[2][2]) * 180 / np.pi\n",
    "        \n",
    "        # Bin values\n",
    "        bins = np.array(range(-99, 99, 3))\n",
    "        binned_labels = np.digitize([yaw, pitch, roll], bins) - 1\n",
    "    \n",
    "        cont_labels = [yaw, pitch, roll]\n",
    "    \n",
    "        return binned_labels, cont_labels\n",
    "\n",
    "    def __gen_filename_list(self, filename_list_file):\n",
    "        if not os.path.exists(filename_list_file):\n",
    "            with open(filename_list_file, 'w+') as tlf:\n",
    "                for root, dirs, files in os.walk(self.data_dir):\n",
    "                    for subdir in dirs:\n",
    "                        subfiles = os.listdir(os.path.join(self.data_dir, subdir))\n",
    "                    \n",
    "                        for f in subfiles:\n",
    "                            if os.path.splitext(f)[1] == '.png':\n",
    "                                token = os.path.splitext(f)[0].split('_')\n",
    "                                filename = token[0] + '_' + token[1]\n",
    "                                # print(filename)\n",
    "                                tlf.write(subdir + '/' + filename + '\\n')\n",
    "    \n",
    "    def __gen_train_test_file(self, train_file, test_file, ratio=0.8):\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        return split_samples(os.path.join(self.data_dir, self.data_file), self.train_file, self.test_file, ratio=ratio)\n",
    "    \n",
    "    def train_num(self):\n",
    "        return self.train_num\n",
    "    \n",
    "    def test_num(self):\n",
    "        return self.test_num\n",
    "    \n",
    "    def save_test(self, name, save_dir, prediction):\n",
    "        img_path = os.path.join(self.data_dir, name + '_rgb.png')\n",
    "        # print(img_path)\n",
    "    \n",
    "        cv2_img = cv2.imread(img_path)\n",
    "        cv2_img = utils.draw_axis(cv2_img, prediction[0], prediction[1], prediction[2], tdx=200, tdy=200,\n",
    "                            size=100)\n",
    "        save_path = os.path.join(save_dir, name.split('/')[1] + '.png')\n",
    "        # print(save_path)\n",
    "        cv2.imwrite(save_path, cv2_img)\n",
    "        \n",
    "    def data_generator(self, shuffle=True, test=False):\n",
    "        sample_file = self.train_file\n",
    "        if test:\n",
    "            sample_file = self.test_file\n",
    "    \n",
    "        filenames = get_list_from_filenames(sample_file)\n",
    "        file_num = len(filenames)\n",
    "        \n",
    "        while True:\n",
    "            if shuffle and not test:\n",
    "                idx = np.random.permutation(range(file_num))\n",
    "                filenames = np.array(filenames)[idx]\n",
    "            max_num = file_num - (file_num % self.batch_size)\n",
    "            for i in range(0, max_num, self.batch_size):\n",
    "                batch_x = []\n",
    "                batch_yaw = []\n",
    "                batch_pitch = []\n",
    "                batch_roll = []\n",
    "                names = []\n",
    "                for j in range(self.batch_size):\n",
    "                    img = self.__get_input_img(self.data_dir, filenames[i + j])\n",
    "                    bin_labels, cont_labels = self.__get_input_label(self.data_dir, filenames[i + j])\n",
    "                    #print(img.shape)\n",
    "                    batch_x.append(img)\n",
    "                    batch_yaw.append([bin_labels[0], cont_labels[0]])\n",
    "                    batch_pitch.append([bin_labels[1], cont_labels[1]])\n",
    "                    batch_roll.append([bin_labels[2], cont_labels[2]])\n",
    "                    names.append(filenames[i + j])\n",
    "                    \n",
    "                batch_x = np.array(batch_x, dtype=np.float32)\n",
    "                batch_yaw = np.array(batch_yaw)\n",
    "                batch_pitch = np.array(batch_pitch)\n",
    "                batch_roll = np.array(batch_roll)\n",
    "                \n",
    "                if test:\n",
    "                    yield (batch_x, [batch_yaw, batch_pitch, batch_roll], names)\n",
    "                else:\n",
    "                    yield (batch_x, [batch_yaw, batch_pitch, batch_roll])\n",
    "            if test:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kevin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kevin/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/kevin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Model)                multiple             23587712    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           resnet50[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100352)       0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "yaw (Dense)                     (None, 66)           6623298     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pitch (Dense)                   (None, 66)           6623298     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "roll (Dense)                    (None, 66)           6623298     dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 43,457,606\n",
      "Trainable params: 43,404,486\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/kevin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-98448cb2db7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHopenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBIN_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINPUT_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBIWI_MODEL_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# net.test(BIWI_TEST_SAVE_DIR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-caf1fcd17332>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, max_epoches, load_weight)\u001b[0m\n\u001b[1;32m     81\u001b[0m                                     \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                                     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                                     verbose=1)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples_or_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "AFLW2000_DATA_DIR = '/opt/Documents/I.F.I-Vietnam/COURS_IFI/TPE/My work/datasets/AFLW2000'\n",
    "AFLW2000_MODEL_FILE = 'models/aflw2000_model.h5'\n",
    "AFLW2000_TEST_SAVE_DIR = '/opt/Documents/I.F.I-Vietnam/COURS_IFI/TPE/My work/datasets/AFLW2000_test/'\n",
    "\n",
    "BIWI_DATA_DIR = '/opt/Documents/I.F.I-Vietnam/COURS_IFI/TPE/My work/BIWI'\n",
    "BIWI_MODEL_FILE = 'models/biwi_model.h5'\n",
    "BIWI_TEST_SAVE_DIR = '/opt/Documents/I.F.I-Vietnam/COURS_IFI/TPE/My work/biwi_test/'\n",
    "\n",
    "face_landmark_path = 'models/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "\n",
    "dataset = Biwi(BIWI_DATA_DIR, '/opt/Documents/I.F.I-Vietnam/COURS_IFI/TPE/My work/datasets/BIWI/filename_list.txt', batch_size=BATCH_SIZE, ratio=0.95)\n",
    "\n",
    "net = Hopenet(dataset, BIN_NUM, batch_size=BATCH_SIZE, input_size=INPUT_SIZE)\n",
    "\n",
    "net.train(BIWI_MODEL_FILE, max_epoches=EPOCHS, load_weight=False)\n",
    "\n",
    "# net.test(BIWI_TEST_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
